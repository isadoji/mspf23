{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "# PR y F1\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from collections import Counter \n",
    "\n",
    "data = pd.read_csv(\"output/pid.csv\")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.value_counts(data['pid'], sort = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['pid'] != 106, \"pid\"] = 0\n",
    "data.loc[data['pid'] == 106, \"pid\"] = 1\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data[4:]\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataset = data[(data[\"pid\"] == 101) | (data[\"pid\"] == 1) | (data[\"pid\"] == 106) |  (data[\"pid\"] == 27) ]#proton, pions, K, lambda\n",
    "#dataset = data[(data[\"pid\"] == 101) | (data[\"pid\"] == 1)| (data[\"pid\"] == 106)]\n",
    "\n",
    "print(pd.value_counts(dataset['pid'], sort = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataset['pid']\n",
    "X = dataset.drop('pid',axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear modelo de regresión lineal simple con el conjunto de entrenamiento\n",
    "regresion_lineal = LinearRegression() # crear lel objeto de Regresión Linear\n",
    "\n",
    "#Ajustar el modelo usando el modelo de la clase (debe tener mismo numero de filas tanto x como y)\n",
    "regresion_lineal.fit(X_train, Y_train)\n",
    "\n",
    "#Creando un vector de predicciones, se debe tomar solo los valores independientes\n",
    "Y_pred = regresion_lineal.predict(X_test)\n",
    "\n",
    "# Error Cuadrado Medio\n",
    "\n",
    "print(\"Mean squared error: %.2f\" % np.sqrt(mean_squared_error(Y_test, Y_pred)))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(Y_test, Y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot with actual and predicted values\n",
    "plt.scatter(Y_test, Y_pred)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LogisticRegression()\n",
    "lr = LogisticRegression(C=1.0,penalty='l2',random_state=1,solver=\"newton-cg\")\n",
    "\n",
    "lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = lr.predict(X_test)\n",
    "print('beta_0:',lr.intercept_)\n",
    "print('beta_1:',lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion matrix', size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Generamos un clasificador sin entrenar ,  0 a todo\n",
    "ns_probs = [0 for _ in range(len(Y_test))]\n",
    "# Predecimos las probabilidades entrenando con lr\n",
    "lr_probs = lr.predict_proba(X_test)\n",
    "#Nos quedamos con las probabilidades de la clase positiva (la probabilidad de 1)\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# Calculamos el AUC\n",
    "ns_auc = roc_auc_score(Y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(Y_test, lr_probs)\n",
    "print('Sin entrenar: ROC AUC=%.3f' % (ns_auc))\n",
    "#print('Regresión Logística: ROC AUC=%.3f' % (lr_auc))\n",
    "# Calculamos las curvas ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(Y_test, lr_probs)\n",
    "\n",
    "\n",
    "# PR y F1\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(Y_test, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(Y_test, Y_pred), auc(lr_recall, lr_precision)\n",
    "print('Regresión Logística: auc=%.3f f1=%.3f ' % (lr_auc, lr_f1))\n",
    "no_train = len(Y_test[Y_test==1]) / len(Y_test)\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Sin entrenar')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Regresión Logística')\n",
    "plt.xlabel('Falsos Positivos')\n",
    "plt.ylabel('Verdaderos Positivos')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot([0, 1], [no_train, no_train], linestyle='--', label='Sin entrenar')\n",
    "plt.plot(lr_recall, lr_precision, marker='.', label='Regresión Logística')\n",
    "#Etiquetas de ejes\n",
    "plt.xlabel('Sensibilidad')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. Normalizar\n",
    "2. Balancear"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "819112c24f0d6b36d35f6c5653e120a0c93a25f82bf2809eaf9b65613f02e80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
