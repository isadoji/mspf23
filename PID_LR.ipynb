{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score , accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "# PR y F1\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from collections import Counter \n",
    "\n",
    "data = pd.read_csv(\"output/pid.csv\")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_matrix(data): #matriz de correlación\n",
    "    correlation = data.corr()\n",
    "    sns.heatmap(correlation, annot=True, fmt=\".1f\", cbar=True, cmap=\"RdYlGn\")\n",
    "\n",
    "corr_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.value_counts(data['pid'], sort = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['pid'] != 1, \"pid\"] = 0\n",
    "data.loc[data['pid'] == 1, \"pid\"] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = data[(data[\"pid\"] == 101) | (data[\"pid\"] == 1) | (data[\"pid\"] == 106) |  (data[\"pid\"] == 27) ]#proton, pions, K, lambda\n",
    "#dataset = data[(data[\"pid\"] == 101) | (data[\"pid\"] == 1)| (data[\"pid\"] == 106)]\n",
    "dataset = data[4:]\n",
    "print(pd.value_counts(dataset['pid'], sort = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.displot(dataset, x=\"pt\", hue=\"pid\", kind=\"kde\",clip=(0.0, 100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(dataset, hue='pid', height=2.25)# hue separar por alguna categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataset['pid']\n",
    "X = dataset.drop('pid',axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear modelo de regresión lineal simple con el conjunto de entrenamiento\n",
    "regresion_lineal = LinearRegression() # crear lel objeto de Regresión Linear\n",
    "\n",
    "#Ajustar el modelo usando el modelo de la clase (debe tener mismo numero de filas tanto x como y)\n",
    "regresion_lineal.fit(X_train, Y_train)\n",
    "\n",
    "#Creando un vector de predicciones, se debe tomar solo los valores independientes\n",
    "Y_pred = regresion_lineal.predict(X_test)\n",
    "\n",
    "# Error Cuadrado Medio\n",
    "\n",
    "print(\"Mean squared error: %.2f\" % np.sqrt(mean_squared_error(Y_test, Y_pred)))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(Y_test, Y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot with actual and predicted values\n",
    "plt.scatter(Y_test, Y_pred)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LogisticRegression()\n",
    "lr = LogisticRegression(C=1.0,penalty='l2',random_state=1,solver=\"newton-cg\",class_weight=\"balanced\")\n",
    "lr.fit(X_train,Y_train)\n",
    "Y_pred = lr.predict(X_test)\n",
    "print('beta_0:',lr.intercept_)\n",
    "print('beta_1:',lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X_train, X_test, Y_train, Y_test):\n",
    "    clf_base = LogisticRegression(C=1.0,penalty='l2',random_state=1,solver=\"newton-cg\")\n",
    "    #clf_base = LogisticRegression(C=1.0,penalty='l2',random_state=1,solver=\"newton-cg\",class_weight=\"balanced\")\n",
    "    clf_base.fit(X_train, Y_train)\n",
    "    return clf_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(X_test, Y_test, Y_pred):\n",
    "    #Generamos un clasificador sin entrenar ,  0 a todo\n",
    "    ns_probs = [0 for _ in range(len(Y_test))]\n",
    "    # Predecimos las probabilidades entrenando con lr\n",
    "    lr_probs = model.predict_proba(X_test)\n",
    "    #Nos quedamos con las probabilidades de la clase positiva (la probabilidad de 1)\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    # Calculamos el AUC\n",
    "    ns_auc = roc_auc_score(Y_test, ns_probs)\n",
    "    lr_auc = roc_auc_score(Y_test, lr_probs)\n",
    "    #print('Regresión Logística: ROC AUC=%.3f' % (lr_auc))\n",
    "    # Calculamos las curvas ROC\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(Y_test, lr_probs)\n",
    "\n",
    "    conf_matrix = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap = 'Blues_r')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "    print (classification_report(Y_test, Y_pred))\n",
    "\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(Y_test, lr_probs)\n",
    "    lr_f1, lr_auc = f1_score(Y_test, Y_pred), auc(lr_recall, lr_precision)\n",
    "    #print('Sin entrenar: ROC AUC=%.3f' % (ns_auc))\n",
    "    print('Regresión Logística: auc=%.3f f1=%.3f ' % (lr_auc, lr_f1))\n",
    "    no_train = len(Y_test[Y_test==1]) / len(Y_test)\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Sin entrenar')\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label='Regresión Logística')\n",
    "    plt.xlabel('Falsos Positivos')\n",
    "    plt.ylabel('Verdaderos Positivos')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot([0, 1], [no_train, no_train], linestyle='--', label='Sin entrenar')\n",
    "    plt.plot(lr_recall, lr_precision, marker='.', label='Regresión Logística')\n",
    "    #Etiquetas de ejes\n",
    "    plt.xlabel('Sensibilidad')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run_model(X_train, X_test, Y_train, Y_test)\n",
    "pred_y = model.predict(X_test)\n",
    "show_result(X_test, Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_us = SMOTE()\n",
    "X_train_res, Y_train_res = os_us.fit_resample(X_train, Y_train)\n",
    " \n",
    "print (\"before resampling {}\".format(Counter(Y_train)))\n",
    "print (\"after resampling {}\".format(Counter(Y_train_res)))\n",
    " \n",
    "model = run_model(X_train_res, X_test, Y_train_res, Y_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "show_result(X_test,Y_test, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "819112c24f0d6b36d35f6c5653e120a0c93a25f82bf2809eaf9b65613f02e80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
